thpool.c and thpool.h are from https://github.com/Pithikos/C-Thread-Pool/blob/master/example.c
The idea here was to make a pt-states.txt search multithreaded to speed things up. What I found
was that it didn't help at all :(  The reason being our bottleneck is how fast we can read a prune
table node from memory...if you have multiple threads trying to read from memory they are all hitting
the same bottleneck.


diff --git a/Makefile b/Makefile
index c30b5dc..3613cd0 100644
--- a/Makefile
+++ b/Makefile
@@ -4,8 +4,7 @@ clean:
 	find . -name __pycache__ | xargs rm -rf
 
 init: clean
-	gcc -O3 -o ida_search_via_graph rubikscubennnsolver/ida_search_core.c rubikscubennnsolver/rotate_xxx.c rubikscubennnsolver/ida_search_666.c rubikscubennnsolver/ida_search_777.c rubikscubennnsolver/ida_search_via_graph.c -lm
-
+	gcc -O3 -o ida_search_via_graph rubikscubennnsolver/ida_search_core.c rubikscubennnsolver/rotate_xxx.c rubikscubennnsolver/ida_search_666.c rubikscubennnsolver/ida_search_777.c rubikscubennnsolver/ida_search_via_graph.c rubikscubennnsolver/thpool.c -pthread -lm
 	python3 -m venv venv
 	@./venv/bin/python3 -m pip install -U pip==20.3.1
 	@./venv/bin/python3 -m pip install -r requirements.dev.txt
diff --git a/rubikscubennnsolver/ida_search_via_graph.c b/rubikscubennnsolver/ida_search_via_graph.c
index 7a57ffc..db2897c 100644
--- a/rubikscubennnsolver/ida_search_via_graph.c
+++ b/rubikscubennnsolver/ida_search_via_graph.c
@@ -3,8 +3,10 @@
 #include <limits.h>
 #include <locale.h>
 #include <math.h>
+#include <pthread.h>
 #include <stdarg.h>
 #include <stdio.h>
+#include <stdint.h>
 #include <stdlib.h>
 #include <string.h>
 #include <sys/resource.h>
@@ -15,6 +17,7 @@
 #include "ida_search_666.h"
 #include "ida_search_777.h"
 #include "ida_search_core.h"
+#include "thpool.h"
 
 unsigned long long ida_count = 0;
 unsigned long long ida_count_total = 0;
@@ -34,6 +37,8 @@ unsigned int pt1_state_max = 0;
 unsigned int pt2_state_max = 0;
 unsigned int pt4_state_max = 0;
 unsigned int call_pt_simple = 0;
+struct ida_search_result search_result;
+unsigned int pt_states_ida_count_total = 0;
 
 #define MAX_IDA_THRESHOLD 20
 char pt_max = -1;
@@ -82,6 +87,21 @@ struct cost_to_goal_result {
     unsigned char perfect_hash34_cost;
 };
 
+typedef struct ida_solve_args {
+    char *cube;
+    unsigned int cube_size;
+    lookup_table_type type;
+    unsigned int pt0_state;
+    unsigned int pt1_state;
+    unsigned int pt2_state;
+    unsigned int pt3_state;
+    unsigned int pt4_state;
+    unsigned char min_ida_threshold;
+    unsigned char max_ida_threshold;
+    unsigned char use_uthash;
+    unsigned char find_extra;
+} ida_solve_args;
+
 unsigned int lr_centers_stage_555[9][9] = {
     /*
     The following is a 2D array that estimates the number of moves to stage LR centers based on the t-center cost
@@ -1050,11 +1070,11 @@ unsigned char parity_ok(char *cube, lookup_table_type type, move_type *moves_to_
     return 1;
 }
 
-struct ida_search_result ida_search(char *cube, unsigned int cube_size, lookup_table_type type,
-                                    unsigned int init_pt0_state, unsigned int init_pt1_state,
-                                    unsigned int init_pt2_state, unsigned int init_pt3_state,
-                                    unsigned int init_pt4_state, unsigned char use_uthash) {
-    struct ida_search_result search_result;
+void
+ida_search(char *cube, unsigned int cube_size, lookup_table_type type,
+           unsigned int init_pt0_state, unsigned int init_pt1_state,
+           unsigned int init_pt2_state, unsigned int init_pt3_state,
+           unsigned int init_pt4_state, unsigned char use_uthash) {
     unsigned char cost_to_goal = 0;
     unsigned char f_cost = 0;
     unsigned int offset[legal_move_count];
@@ -1075,7 +1095,7 @@ struct ida_search_result ida_search(char *cube, unsigned int cube_size, lookup_t
     unsigned int pt3_state_offset = 0;
     unsigned int pt4_state_offset = 0;
     move_type move;
-    search_result.found_solution = 0;
+    // search_result.found_solution = 0;
     char key[64];
     move_type *prev_move_move_matrix = NULL;
     char cube_tmp[array_size];
@@ -1121,7 +1141,7 @@ struct ida_search_result ida_search(char *cube, unsigned int cube_size, lookup_t
                 }
 
                 if (solution_count >= min_solution_count) {
-                    return search_result;
+                    return;
                 }
             }
 
@@ -1355,16 +1375,33 @@ struct ida_search_result ida_search(char *cube, unsigned int cube_size, lookup_t
         }
         free(node);
     }
-
-    return search_result;
 }
 
+/*
 struct ida_search_result ida_solve(char *cube, unsigned int cube_size, lookup_table_type type, unsigned int pt0_state,
                                    unsigned int pt1_state, unsigned int pt2_state, unsigned int pt3_state,
                                    unsigned int pt4_state, unsigned char min_ida_threshold,
                                    unsigned char max_ida_threshold, unsigned char use_uthash,
                                    unsigned char find_extra) {
-    struct ida_search_result search_result;
+                                       */
+// dwalton
+void
+ida_solve(void *args) {
+    struct ida_solve_args *myargs = (struct ida_solve_args *) args;
+    char *cube = myargs->cube;
+    unsigned int cube_size = myargs->cube_size;
+    lookup_table_type type = myargs->type;
+    unsigned int pt0_state = myargs->pt0_state;
+    unsigned int pt1_state = myargs->pt1_state;
+    unsigned int pt2_state = myargs->pt2_state;
+    unsigned int pt3_state = myargs->pt3_state;
+    unsigned int pt4_state = myargs->pt4_state;
+    unsigned char min_ida_threshold = myargs->min_ida_threshold;
+    unsigned char max_ida_threshold = myargs->max_ida_threshold;
+    unsigned char use_uthash = myargs->use_uthash;
+    unsigned char find_extra = myargs->find_extra;
+    free(args);
+
     struct timeval stop, start, start_this_threshold;
     unsigned char pt0_cost = 0;
     unsigned char pt1_cost = 0;
@@ -1376,18 +1413,17 @@ struct ida_search_result ida_solve(char *cube, unsigned int cube_size, lookup_ta
 
     // For printing commas via %'d
     setlocale(LC_NUMERIC, "");
-    search_result.found_solution = 0;
 
     if (min_ida_threshold > max_ida_threshold) {
         LOG("min_ida_threshold %d > max_ida_threshold %d\n", min_ida_threshold, max_ida_threshold);
-        return search_result;
+        return;
     }
 
     ctg = pt_states_to_cost(cube, type, pt0_state, pt1_state, pt2_state, pt3_state, pt4_state);
 
     if (ctg.cost_to_goal > max_ida_threshold) {
         // LOG("ctg.cost_to_goal %d > min_ida_threshold %d\n", ctg.cost_to_goal, min_ida_threshold);
-        return search_result;
+        return;
     }
     LOG("cost_to_goal %d, pt0_state %d, pt1_state %d, pt2_state %d, pt3_state %d, pt4_state %d\n",
          ctg.cost_to_goal, pt0_state, pt1_state, pt2_state, pt3_state, pt4_state);
@@ -1400,13 +1436,12 @@ struct ida_search_result ida_solve(char *cube, unsigned int cube_size, lookup_ta
         gettimeofday(&start_this_threshold, NULL);
         hash_delete_all(&ida_explored);
 
-        search_result =
-            ida_search(cube, cube_size, type, pt0_state, pt1_state, pt2_state, pt3_state, pt4_state, use_uthash);
+        ida_search(cube, cube_size, type, pt0_state, pt1_state, pt2_state, pt3_state, pt4_state, use_uthash);
 
         gettimeofday(&stop, NULL);
         ida_count_total += ida_count;
+        pt_states_ida_count_total += ida_count;
 
-        // dwalton reference
         float us = ((stop.tv_sec - start_this_threshold.tv_sec) * 1000000) +
                    ((stop.tv_usec - start_this_threshold.tv_usec));
         float nodes_per_us = ida_count / us;
@@ -1418,17 +1453,16 @@ struct ida_search_result ida_solve(char *cube, unsigned int cube_size, lookup_ta
             float us = ((stop.tv_sec - start.tv_sec) * 1000000) + ((stop.tv_usec - start.tv_usec));
             float nodes_per_us = ida_count_total / us;
             unsigned int nodes_per_sec = nodes_per_us * 1000000;
-            LOG("IDA found solution, explored %'llu total nodes, took %.3fs, %'llu nodes-per-sec\n\n", ida_count_total,
+            LOG("IDA found solution, thread #%u, explored %'llu total nodes, took %.3fs, %'llu nodes-per-sec\n\n",  (int)pthread_self(), ida_count_total,
                 us / 1000000, nodes_per_sec);
 
             if (solution_count >= min_solution_count || !find_extra) {
-                return search_result;
+                return;
             }
         }
     }
 
     LOG("IDA failed with range %d->%d\n\n", min_ida_threshold, max_ida_threshold);
-    return search_result;
 }
 
 char *read_file(char *filename) {
@@ -1498,10 +1532,11 @@ int main(int argc, char *argv[]) {
     unsigned int cube_size = 0;
     char kociemba[300];
     char *cube = NULL;
-    struct ida_search_result search_result;
+    struct ida_solve_args *args;
     memset(kociemba, 0, sizeof(char) * 300);
     memset(legal_moves, MOVE_NONE, MOVE_MAX);
     memset(move_matrix, MOVE_NONE, MOVE_MAX * MOVE_MAX);
+    memset(&search_result, 0, sizeof(struct ida_search_result));
     search_result.found_solution = 0;
     search_result.f_cost = 99;
 
@@ -2005,7 +2040,8 @@ int main(int argc, char *argv[]) {
         min_search_result.found_solution = 0;
         min_search_result.f_cost = 99;
         struct timeval pt_states_start, pt_states_stop;
-        unsigned int pt_states_ida_count_total = 0;
+        unsigned char use_threads = 1;
+        threadpool thpool;
 
         if (access(prune_table_states_filename, F_OK) != 0) {
             printf("ERROR: file %s not found\n", prune_table_states_filename);
@@ -2014,10 +2050,19 @@ int main(int argc, char *argv[]) {
 
         gettimeofday(&pt_states_start, NULL);
 
+        // dwalton this needs more work...there was a bug here so I hard-coded this to 13 for the
+        // experiment I was running.
+        min_ida_threshold = 13;
+        max_ida_threshold = 13;
+
         for (unsigned char i_ida_threshold = min_ida_threshold; i_ida_threshold <= max_ida_threshold;
              i_ida_threshold++) {
             LOG("loop %d/%d\n", i_ida_threshold, max_ida_threshold);
 
+            if (use_threads) {
+                thpool = thpool_init(8);
+            }
+
             fh_read = fopen(prune_table_states_filename, "r");
             while ((read = getline(&line, &len, fh_read)) != -1) {
                 // printf("%s", line);
@@ -2043,22 +2088,43 @@ int main(int argc, char *argv[]) {
                     token_index++;
                 }
 
-                search_result = ida_solve(cube, cube_size, type, prune_table_0_state, prune_table_1_state,
-                                          prune_table_2_state, prune_table_3_state, prune_table_4_state,
-                                          i_ida_threshold, i_ida_threshold, use_uthash, find_extra);
-                pt_states_ida_count_total += ida_count;
+                args = malloc(sizeof(struct ida_solve_args));
+                args->cube = cube;
+                args->cube_size = cube_size;
+                args->type = type;
+                args->pt0_state = prune_table_0_state;
+                args->pt1_state = prune_table_1_state;
+                args->pt2_state = prune_table_2_state;
+                args->pt3_state = prune_table_3_state;
+                args->pt4_state = prune_table_4_state;
+                args->min_ida_threshold = i_ida_threshold;
+                args->max_ida_threshold = i_ida_threshold;
+                args->use_uthash = use_uthash;
+                args->find_extra = find_extra;
+
+                // dwalton
+                // use threads
+                if (use_threads) {
+                    // thpool_add_work(thpool, task, (void*)(uintptr_t)i);
+                    thpool_add_work(thpool, ida_solve, (void *) args);
+                    // pt_states_ida_count_total += ida_count;
 
-                if (search_result.found_solution) {
-                    if (search_result.f_cost < min_search_result.f_cost) {
-                        min_search_result = search_result;
-                    }
+                } else {
+                    ida_solve(args);
+                    pt_states_ida_count_total += ida_count;
 
-                    if (find_extra) {
-                        if (solution_count >= min_solution_count) {
+                    if (search_result.found_solution) {
+                        if (search_result.f_cost < min_search_result.f_cost) {
+                            min_search_result = search_result;
+                        }
+
+                        if (find_extra) {
+                            if (solution_count >= min_solution_count) {
+                                break;
+                            }
+                        } else {
                             break;
                         }
-                    } else {
-                        break;
                     }
                 }
 
@@ -2066,6 +2132,12 @@ int main(int argc, char *argv[]) {
             }
             fclose(fh_read);
 
+            if (use_threads) {
+                thpool_wait(thpool);
+                LOG("Killing threadpool\n");
+                thpool_destroy(thpool);
+            }
+
             search_result = min_search_result;
 
             if (search_result.found_solution) {
@@ -2099,9 +2171,20 @@ int main(int argc, char *argv[]) {
                 min_ida_threshold = ctg.cost_to_goal;
             }
 
-            search_result = ida_solve(cube, cube_size, type, prune_table_0_state, prune_table_1_state, prune_table_2_state,
-                                      prune_table_3_state, prune_table_4_state, min_ida_threshold, max_ida_threshold,
-                                      use_uthash, find_extra);
+            args = malloc(sizeof(struct ida_solve_args));
+            args->cube = cube;
+            args->cube_size = cube_size;
+            args->type = type;
+            args->pt0_state = prune_table_0_state;
+            args->pt1_state = prune_table_1_state;
+            args->pt2_state = prune_table_2_state;
+            args->pt3_state = prune_table_3_state;
+            args->pt4_state = prune_table_4_state;
+            args->min_ida_threshold = min_ida_threshold;
+            args->max_ida_threshold = max_ida_threshold;
+            args->use_uthash = use_uthash;
+            args->find_extra = find_extra;
+            ida_solve(args);
         }
     }
 
diff --git a/rubikscubennnsolver/thpool.c b/rubikscubennnsolver/thpool.c
new file mode 100644
index 0000000..d320f8f
--- /dev/null
+++ b/rubikscubennnsolver/thpool.c
@@ -0,0 +1,547 @@
+/* ********************************
+ * Author:       Johan Hanssen Seferidis
+ * License:	     MIT
+ * Description:  Library providing a threading pool where you can add
+ *               work. For usage, check the thpool.h file or README.md
+ *
+ *//** @file thpool.h *//*
+ *
+ ********************************/
+
+#define _POSIX_C_SOURCE 200809L
+#include <unistd.h>
+#include <signal.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <pthread.h>
+#include <errno.h>
+#include <time.h>
+#if defined(__linux__)
+#include <sys/prctl.h>
+#endif
+
+#include "thpool.h"
+
+#ifdef THPOOL_DEBUG
+#define THPOOL_DEBUG 1
+#else
+#define THPOOL_DEBUG 0
+#endif
+
+#if !defined(DISABLE_PRINT) || defined(THPOOL_DEBUG)
+#define err(str) fprintf(stderr, str)
+#else
+#define err(str)
+#endif
+
+static volatile int threads_keepalive;
+static volatile int threads_on_hold;
+
+
+
+/* ========================== STRUCTURES ============================ */
+
+
+/* Binary semaphore */
+typedef struct bsem {
+	pthread_mutex_t mutex;
+	pthread_cond_t   cond;
+	int v;
+} bsem;
+
+
+/* Job */
+typedef struct job{
+	struct job*  prev;                   /* pointer to previous job   */
+	void   (*function)(void* arg);       /* function pointer          */
+	void*  arg;                          /* function's argument       */
+} job;
+
+
+/* Job queue */
+typedef struct jobqueue{
+	pthread_mutex_t rwmutex;             /* used for queue r/w access */
+	job  *front;                         /* pointer to front of queue */
+	job  *rear;                          /* pointer to rear  of queue */
+	bsem *has_jobs;                      /* flag as binary semaphore  */
+	int   len;                           /* number of jobs in queue   */
+} jobqueue;
+
+
+/* Thread */
+typedef struct thread{
+	int       id;                        /* friendly id               */
+	pthread_t pthread;                   /* pointer to actual thread  */
+	struct thpool_* thpool_p;            /* access to thpool          */
+} thread;
+
+
+/* Threadpool */
+typedef struct thpool_{
+	thread**   threads;                  /* pointer to threads        */
+	volatile int num_threads_alive;      /* threads currently alive   */
+	volatile int num_threads_working;    /* threads currently working */
+	pthread_mutex_t  thcount_lock;       /* used for thread count etc */
+	pthread_cond_t  threads_all_idle;    /* signal to thpool_wait     */
+	jobqueue  jobqueue;                  /* job queue                 */
+} thpool_;
+
+
+
+
+
+/* ========================== PROTOTYPES ============================ */
+
+
+static int  thread_init(thpool_* thpool_p, struct thread** thread_p, int id);
+static void* thread_do(struct thread* thread_p);
+static void  thread_hold(int sig_id);
+static void  thread_destroy(struct thread* thread_p);
+
+static int   jobqueue_init(jobqueue* jobqueue_p);
+static void  jobqueue_clear(jobqueue* jobqueue_p);
+static void  jobqueue_push(jobqueue* jobqueue_p, struct job* newjob_p);
+static struct job* jobqueue_pull(jobqueue* jobqueue_p);
+static void  jobqueue_destroy(jobqueue* jobqueue_p);
+
+static void  bsem_init(struct bsem *bsem_p, int value);
+static void  bsem_reset(struct bsem *bsem_p);
+static void  bsem_post(struct bsem *bsem_p);
+static void  bsem_post_all(struct bsem *bsem_p);
+static void  bsem_wait(struct bsem *bsem_p);
+
+
+
+
+
+/* ========================== THREADPOOL ============================ */
+
+
+/* Initialise thread pool */
+struct thpool_* thpool_init(int num_threads){
+
+	threads_on_hold   = 0;
+	threads_keepalive = 1;
+
+	if (num_threads < 0){
+		num_threads = 0;
+	}
+
+	/* Make new thread pool */
+	thpool_* thpool_p;
+	thpool_p = (struct thpool_*)malloc(sizeof(struct thpool_));
+	if (thpool_p == NULL){
+		err("thpool_init(): Could not allocate memory for thread pool\n");
+		return NULL;
+	}
+	thpool_p->num_threads_alive   = 0;
+	thpool_p->num_threads_working = 0;
+
+	/* Initialise the job queue */
+	if (jobqueue_init(&thpool_p->jobqueue) == -1){
+		err("thpool_init(): Could not allocate memory for job queue\n");
+		free(thpool_p);
+		return NULL;
+	}
+
+	/* Make threads in pool */
+	thpool_p->threads = (struct thread**)malloc(num_threads * sizeof(struct thread *));
+	if (thpool_p->threads == NULL){
+		err("thpool_init(): Could not allocate memory for threads\n");
+		jobqueue_destroy(&thpool_p->jobqueue);
+		free(thpool_p);
+		return NULL;
+	}
+
+	pthread_mutex_init(&(thpool_p->thcount_lock), NULL);
+	pthread_cond_init(&thpool_p->threads_all_idle, NULL);
+
+	/* Thread init */
+	int n;
+	for (n=0; n<num_threads; n++){
+		thread_init(thpool_p, &thpool_p->threads[n], n);
+#if THPOOL_DEBUG
+			printf("THPOOL_DEBUG: Created thread %d in pool \n", n);
+#endif
+	}
+
+	/* Wait for threads to initialize */
+	while (thpool_p->num_threads_alive != num_threads) {}
+
+	return thpool_p;
+}
+
+
+/* Add work to the thread pool */
+int thpool_add_work(thpool_* thpool_p, void (*function_p)(void*), void* arg_p){
+	job* newjob;
+
+	newjob=(struct job*)malloc(sizeof(struct job));
+	if (newjob==NULL){
+		err("thpool_add_work(): Could not allocate memory for new job\n");
+		return -1;
+	}
+
+	/* add function and argument */
+	newjob->function=function_p;
+	newjob->arg=arg_p;
+
+	/* add job to queue */
+	jobqueue_push(&thpool_p->jobqueue, newjob);
+
+	return 0;
+}
+
+
+/* Wait until all jobs have finished */
+void thpool_wait(thpool_* thpool_p){
+	pthread_mutex_lock(&thpool_p->thcount_lock);
+	while (thpool_p->jobqueue.len || thpool_p->num_threads_working) {
+		pthread_cond_wait(&thpool_p->threads_all_idle, &thpool_p->thcount_lock);
+	}
+	pthread_mutex_unlock(&thpool_p->thcount_lock);
+}
+
+
+/* Destroy the threadpool */
+void thpool_destroy(thpool_* thpool_p){
+	/* No need to destory if it's NULL */
+	if (thpool_p == NULL) return ;
+
+	volatile int threads_total = thpool_p->num_threads_alive;
+
+	/* End each thread 's infinite loop */
+	threads_keepalive = 0;
+
+	/* Give one second to kill idle threads */
+	double TIMEOUT = 1.0;
+	time_t start, end;
+	double tpassed = 0.0;
+	time (&start);
+	while (tpassed < TIMEOUT && thpool_p->num_threads_alive){
+		bsem_post_all(thpool_p->jobqueue.has_jobs);
+		time (&end);
+		tpassed = difftime(end,start);
+	}
+
+	/* Poll remaining threads */
+	while (thpool_p->num_threads_alive){
+		bsem_post_all(thpool_p->jobqueue.has_jobs);
+		sleep(1);
+	}
+
+	/* Job queue cleanup */
+	jobqueue_destroy(&thpool_p->jobqueue);
+	/* Deallocs */
+	int n;
+	for (n=0; n < threads_total; n++){
+		thread_destroy(thpool_p->threads[n]);
+	}
+	free(thpool_p->threads);
+	free(thpool_p);
+}
+
+
+/* Pause all threads in threadpool */
+void thpool_pause(thpool_* thpool_p) {
+	int n;
+	for (n=0; n < thpool_p->num_threads_alive; n++){
+		pthread_kill(thpool_p->threads[n]->pthread, SIGUSR1);
+	}
+}
+
+
+/* Resume all threads in threadpool */
+void thpool_resume(thpool_* thpool_p) {
+    // resuming a single threadpool hasn't been
+    // implemented yet, meanwhile this supresses
+    // the warnings
+    (void)thpool_p;
+
+	threads_on_hold = 0;
+}
+
+
+int thpool_num_threads_working(thpool_* thpool_p){
+	return thpool_p->num_threads_working;
+}
+
+
+
+
+
+/* ============================ THREAD ============================== */
+
+
+/* Initialize a thread in the thread pool
+ *
+ * @param thread        address to the pointer of the thread to be created
+ * @param id            id to be given to the thread
+ * @return 0 on success, -1 otherwise.
+ */
+static int thread_init (thpool_* thpool_p, struct thread** thread_p, int id){
+
+	*thread_p = (struct thread*)malloc(sizeof(struct thread));
+	if (*thread_p == NULL){
+		err("thread_init(): Could not allocate memory for thread\n");
+		return -1;
+	}
+
+	(*thread_p)->thpool_p = thpool_p;
+	(*thread_p)->id       = id;
+
+	pthread_create(&(*thread_p)->pthread, NULL, (void * (*)(void *)) thread_do, (*thread_p));
+	pthread_detach((*thread_p)->pthread);
+	return 0;
+}
+
+
+/* Sets the calling thread on hold */
+static void thread_hold(int sig_id) {
+    (void)sig_id;
+	threads_on_hold = 1;
+	while (threads_on_hold){
+		sleep(1);
+	}
+}
+
+
+/* What each thread is doing
+*
+* In principle this is an endless loop. The only time this loop gets interuppted is once
+* thpool_destroy() is invoked or the program exits.
+*
+* @param  thread        thread that will run this function
+* @return nothing
+*/
+static void* thread_do(struct thread* thread_p){
+
+	/* Set thread name for profiling and debuging */
+	char thread_name[32] = {0};
+	snprintf(thread_name, 32, "thread-pool-%d", thread_p->id);
+
+#if defined(__linux__)
+	/* Use prctl instead to prevent using _GNU_SOURCE flag and implicit declaration */
+	prctl(PR_SET_NAME, thread_name);
+#elif defined(__APPLE__) && defined(__MACH__)
+	pthread_setname_np(thread_name);
+#else
+	err("thread_do(): pthread_setname_np is not supported on this system");
+#endif
+
+	/* Assure all threads have been created before starting serving */
+	thpool_* thpool_p = thread_p->thpool_p;
+
+	/* Register signal handler */
+	struct sigaction act;
+	sigemptyset(&act.sa_mask);
+	act.sa_flags = 0;
+	act.sa_handler = thread_hold;
+	if (sigaction(SIGUSR1, &act, NULL) == -1) {
+		err("thread_do(): cannot handle SIGUSR1");
+	}
+
+	/* Mark thread as alive (initialized) */
+	pthread_mutex_lock(&thpool_p->thcount_lock);
+	thpool_p->num_threads_alive += 1;
+	pthread_mutex_unlock(&thpool_p->thcount_lock);
+
+	while(threads_keepalive){
+
+		bsem_wait(thpool_p->jobqueue.has_jobs);
+
+		if (threads_keepalive){
+
+			pthread_mutex_lock(&thpool_p->thcount_lock);
+			thpool_p->num_threads_working++;
+			pthread_mutex_unlock(&thpool_p->thcount_lock);
+
+			/* Read job from queue and execute it */
+			void (*func_buff)(void*);
+			void*  arg_buff;
+			job* job_p = jobqueue_pull(&thpool_p->jobqueue);
+			if (job_p) {
+				func_buff = job_p->function;
+				arg_buff  = job_p->arg;
+				func_buff(arg_buff);
+				free(job_p);
+			}
+
+			pthread_mutex_lock(&thpool_p->thcount_lock);
+			thpool_p->num_threads_working--;
+			if (!thpool_p->num_threads_working) {
+				pthread_cond_signal(&thpool_p->threads_all_idle);
+			}
+			pthread_mutex_unlock(&thpool_p->thcount_lock);
+
+		}
+	}
+	pthread_mutex_lock(&thpool_p->thcount_lock);
+	thpool_p->num_threads_alive --;
+	pthread_mutex_unlock(&thpool_p->thcount_lock);
+
+	return NULL;
+}
+
+
+/* Frees a thread  */
+static void thread_destroy (thread* thread_p){
+	free(thread_p);
+}
+
+
+
+
+
+/* ============================ JOB QUEUE =========================== */
+
+
+/* Initialize queue */
+static int jobqueue_init(jobqueue* jobqueue_p){
+	jobqueue_p->len = 0;
+	jobqueue_p->front = NULL;
+	jobqueue_p->rear  = NULL;
+
+	jobqueue_p->has_jobs = (struct bsem*)malloc(sizeof(struct bsem));
+	if (jobqueue_p->has_jobs == NULL){
+		return -1;
+	}
+
+	pthread_mutex_init(&(jobqueue_p->rwmutex), NULL);
+	bsem_init(jobqueue_p->has_jobs, 0);
+
+	return 0;
+}
+
+
+/* Clear the queue */
+static void jobqueue_clear(jobqueue* jobqueue_p){
+
+	while(jobqueue_p->len){
+		free(jobqueue_pull(jobqueue_p));
+	}
+
+	jobqueue_p->front = NULL;
+	jobqueue_p->rear  = NULL;
+	bsem_reset(jobqueue_p->has_jobs);
+	jobqueue_p->len = 0;
+
+}
+
+
+/* Add (allocated) job to queue
+ */
+static void jobqueue_push(jobqueue* jobqueue_p, struct job* newjob){
+
+	pthread_mutex_lock(&jobqueue_p->rwmutex);
+	newjob->prev = NULL;
+
+	switch(jobqueue_p->len){
+
+		case 0:  /* if no jobs in queue */
+					jobqueue_p->front = newjob;
+					jobqueue_p->rear  = newjob;
+					break;
+
+		default: /* if jobs in queue */
+					jobqueue_p->rear->prev = newjob;
+					jobqueue_p->rear = newjob;
+
+	}
+	jobqueue_p->len++;
+
+	bsem_post(jobqueue_p->has_jobs);
+	pthread_mutex_unlock(&jobqueue_p->rwmutex);
+}
+
+
+/* Get first job from queue(removes it from queue)
+ * Notice: Caller MUST hold a mutex
+ */
+static struct job* jobqueue_pull(jobqueue* jobqueue_p){
+
+	pthread_mutex_lock(&jobqueue_p->rwmutex);
+	job* job_p = jobqueue_p->front;
+
+	switch(jobqueue_p->len){
+
+		case 0:  /* if no jobs in queue */
+		  			break;
+
+		case 1:  /* if one job in queue */
+					jobqueue_p->front = NULL;
+					jobqueue_p->rear  = NULL;
+					jobqueue_p->len = 0;
+					break;
+
+		default: /* if >1 jobs in queue */
+					jobqueue_p->front = job_p->prev;
+					jobqueue_p->len--;
+					/* more than one job in queue -> post it */
+					bsem_post(jobqueue_p->has_jobs);
+
+	}
+
+	pthread_mutex_unlock(&jobqueue_p->rwmutex);
+	return job_p;
+}
+
+
+/* Free all queue resources back to the system */
+static void jobqueue_destroy(jobqueue* jobqueue_p){
+	jobqueue_clear(jobqueue_p);
+	free(jobqueue_p->has_jobs);
+}
+
+
+
+
+
+/* ======================== SYNCHRONISATION ========================= */
+
+
+/* Init semaphore to 1 or 0 */
+static void bsem_init(bsem *bsem_p, int value) {
+	if (value < 0 || value > 1) {
+		err("bsem_init(): Binary semaphore can take only values 1 or 0");
+		exit(1);
+	}
+	pthread_mutex_init(&(bsem_p->mutex), NULL);
+	pthread_cond_init(&(bsem_p->cond), NULL);
+	bsem_p->v = value;
+}
+
+
+/* Reset semaphore to 0 */
+static void bsem_reset(bsem *bsem_p) {
+	bsem_init(bsem_p, 0);
+}
+
+
+/* Post to at least one thread */
+static void bsem_post(bsem *bsem_p) {
+	pthread_mutex_lock(&bsem_p->mutex);
+	bsem_p->v = 1;
+	pthread_cond_signal(&bsem_p->cond);
+	pthread_mutex_unlock(&bsem_p->mutex);
+}
+
+
+/* Post to all threads */
+static void bsem_post_all(bsem *bsem_p) {
+	pthread_mutex_lock(&bsem_p->mutex);
+	bsem_p->v = 1;
+	pthread_cond_broadcast(&bsem_p->cond);
+	pthread_mutex_unlock(&bsem_p->mutex);
+}
+
+
+/* Wait on semaphore until semaphore has value 0 */
+static void bsem_wait(bsem* bsem_p) {
+	pthread_mutex_lock(&bsem_p->mutex);
+	while (bsem_p->v != 1) {
+		pthread_cond_wait(&bsem_p->cond, &bsem_p->mutex);
+	}
+	bsem_p->v = 0;
+	pthread_mutex_unlock(&bsem_p->mutex);
+}
diff --git a/rubikscubennnsolver/thpool.h b/rubikscubennnsolver/thpool.h
new file mode 100644
index 0000000..af3e68d
--- /dev/null
+++ b/rubikscubennnsolver/thpool.h
@@ -0,0 +1,187 @@
+/**********************************
+ * @author      Johan Hanssen Seferidis
+ * License:     MIT
+ *
+ **********************************/
+
+#ifndef _THPOOL_
+#define _THPOOL_
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/* =================================== API ======================================= */
+
+
+typedef struct thpool_* threadpool;
+
+
+/**
+ * @brief  Initialize threadpool
+ *
+ * Initializes a threadpool. This function will not return until all
+ * threads have initialized successfully.
+ *
+ * @example
+ *
+ *    ..
+ *    threadpool thpool;                     //First we declare a threadpool
+ *    thpool = thpool_init(4);               //then we initialize it to 4 threads
+ *    ..
+ *
+ * @param  num_threads   number of threads to be created in the threadpool
+ * @return threadpool    created threadpool on success,
+ *                       NULL on error
+ */
+threadpool thpool_init(int num_threads);
+
+
+/**
+ * @brief Add work to the job queue
+ *
+ * Takes an action and its argument and adds it to the threadpool's job queue.
+ * If you want to add to work a function with more than one arguments then
+ * a way to implement this is by passing a pointer to a structure.
+ *
+ * NOTICE: You have to cast both the function and argument to not get warnings.
+ *
+ * @example
+ *
+ *    void print_num(int num){
+ *       printf("%d\n", num);
+ *    }
+ *
+ *    int main() {
+ *       ..
+ *       int a = 10;
+ *       thpool_add_work(thpool, (void*)print_num, (void*)a);
+ *       ..
+ *    }
+ *
+ * @param  threadpool    threadpool to which the work will be added
+ * @param  function_p    pointer to function to add as work
+ * @param  arg_p         pointer to an argument
+ * @return 0 on success, -1 otherwise.
+ */
+int thpool_add_work(threadpool, void (*function_p)(void*), void* arg_p);
+
+
+/**
+ * @brief Wait for all queued jobs to finish
+ *
+ * Will wait for all jobs - both queued and currently running to finish.
+ * Once the queue is empty and all work has completed, the calling thread
+ * (probably the main program) will continue.
+ *
+ * Smart polling is used in wait. The polling is initially 0 - meaning that
+ * there is virtually no polling at all. If after 1 seconds the threads
+ * haven't finished, the polling interval starts growing exponentially
+ * until it reaches max_secs seconds. Then it jumps down to a maximum polling
+ * interval assuming that heavy processing is being used in the threadpool.
+ *
+ * @example
+ *
+ *    ..
+ *    threadpool thpool = thpool_init(4);
+ *    ..
+ *    // Add a bunch of work
+ *    ..
+ *    thpool_wait(thpool);
+ *    puts("All added work has finished");
+ *    ..
+ *
+ * @param threadpool     the threadpool to wait for
+ * @return nothing
+ */
+void thpool_wait(threadpool);
+
+
+/**
+ * @brief Pauses all threads immediately
+ *
+ * The threads will be paused no matter if they are idle or working.
+ * The threads return to their previous states once thpool_resume
+ * is called.
+ *
+ * While the thread is being paused, new work can be added.
+ *
+ * @example
+ *
+ *    threadpool thpool = thpool_init(4);
+ *    thpool_pause(thpool);
+ *    ..
+ *    // Add a bunch of work
+ *    ..
+ *    thpool_resume(thpool); // Let the threads start their magic
+ *
+ * @param threadpool    the threadpool where the threads should be paused
+ * @return nothing
+ */
+void thpool_pause(threadpool);
+
+
+/**
+ * @brief Unpauses all threads if they are paused
+ *
+ * @example
+ *    ..
+ *    thpool_pause(thpool);
+ *    sleep(10);              // Delay execution 10 seconds
+ *    thpool_resume(thpool);
+ *    ..
+ *
+ * @param threadpool     the threadpool where the threads should be unpaused
+ * @return nothing
+ */
+void thpool_resume(threadpool);
+
+
+/**
+ * @brief Destroy the threadpool
+ *
+ * This will wait for the currently active threads to finish and then 'kill'
+ * the whole threadpool to free up memory.
+ *
+ * @example
+ * int main() {
+ *    threadpool thpool1 = thpool_init(2);
+ *    threadpool thpool2 = thpool_init(2);
+ *    ..
+ *    thpool_destroy(thpool1);
+ *    ..
+ *    return 0;
+ * }
+ *
+ * @param threadpool     the threadpool to destroy
+ * @return nothing
+ */
+void thpool_destroy(threadpool);
+
+
+/**
+ * @brief Show currently working threads
+ *
+ * Working threads are the threads that are performing work (not idle).
+ *
+ * @example
+ * int main() {
+ *    threadpool thpool1 = thpool_init(2);
+ *    threadpool thpool2 = thpool_init(2);
+ *    ..
+ *    printf("Working threads: %d\n", thpool_num_threads_working(thpool1));
+ *    ..
+ *    return 0;
+ * }
+ *
+ * @param threadpool     the threadpool of interest
+ * @return integer       number of threads working
+ */
+int thpool_num_threads_working(threadpool);
+
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif
